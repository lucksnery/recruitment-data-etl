# Projeto 1 ‚Äî Pipeline ETL Simples (Python + SQL + Streamlit)

## üìå Descri√ß√£o Geral
Este projeto tem como objetivo a constru√ß√£o de um **pipeline ETL (Extract, Transform, Load)** simples, simulando um **cen√°rio real de recrutamento**, onde dados de candidatos s√£o coletados por meio de **formul√°rios web** e frequentemente apresentam **inconsist√™ncias, falta de padroniza√ß√£o e erros de preenchimento**.

O pipeline realiza a **extra√ß√£o dos dados brutos**, o **tratamento e padroniza√ß√£o**, o **armazenamento em banco de dados relacional** e, por fim, a **visualiza√ß√£o das informa√ß√µes em um dashboard interativo** desenvolvido com Streamlit.

---

## üõ†Ô∏è Tecnologias Utilizadas
- **Python**
- **Pandas**
- **SQLite**
- **Streamlit**
- **CSV (dados brutos)**

---

## 1Ô∏è‚É£ Gera√ß√£o do Arquivo CSV (Dados Brutos)
Nesta etapa, √© criado um arquivo **CSV** que simula dados coletados a partir de um **formul√°rio online utilizado por recrutadores**.

Os dados s√£o preenchidos por candidatos e **n√£o seguem um padr√£o consistente**, apresentando problemas comuns do mundo real, como:
- Datas de nascimento em diferentes formatos  
- Pretens√£o salarial preenchida como texto, n√∫meros ou valores incompletos  
- Informa√ß√µes de localiza√ß√£o inconsistentes (cidade, estado, abrevia√ß√µes, erros de digita√ß√£o)  
- Campos vazios ou inv√°lidos  

O objetivo desta etapa √© **simular um cen√°rio realista de dados desestruturados**, semelhante ao encontrado em ambientes corporativos.

---

## 2Ô∏è‚É£ Extra√ß√£o e Tratamento dos Dados (Python + Pandas)
Os dados do arquivo CSV s√£o carregados utilizando **Python com a biblioteca Pandas**, sendo transformados em um **DataFrame** para facilitar o processamento.

Nesta fase, s√£o realizadas opera√ß√µes de **limpeza e padroniza√ß√£o**, como:
- Normaliza√ß√£o de formatos de data  
- Convers√£o de campos num√©ricos (ex: pretens√£o salarial)  
- Tratamento de valores nulos ou inv√°lidos  
- Padroniza√ß√£o de textos (ex: cidade, estado, cargo)  
- Valida√ß√£o b√°sica dos dados  

Essa etapa corresponde √† fase **Transform** do pipeline ETL.

---

## 3Ô∏è‚É£ Carga dos Dados no Banco de Dados (SQLite)
Ap√≥s o tratamento, os dados s√£o carregados em um banco de dados **SQLite**, estruturando as informa√ß√µes em tabelas organizadas.

Nesta etapa:
- O banco de dados √© criado automaticamente (caso n√£o exista)  
- Os dados tratados s√£o inseridos de forma estruturada  
- O banco passa a servir como **fonte confi√°vel para an√°lises futuras**  

Essa fase representa a etapa **Load** do processo ETL.

---

## 4Ô∏è‚É£ Visualiza√ß√£o e Dashboard com Streamlit
Por fim, √© desenvolvido um **dashboard interativo utilizando Streamlit**, que consome os dados armazenados no SQLite.

O dashboard apresenta:
- Indicadores gerais (quantidade de candidatos, m√©dia salarial, etc.)  
- Gr√°ficos interativos (distribui√ß√£o por localiza√ß√£o, faixa salarial, idade, etc.)  
- Tabelas din√¢micas para consulta dos dados  
- Filtros interativos para an√°lise explorat√≥ria  

O objetivo desta etapa √© **transformar dados brutos em informa√ß√µes visuais claras e acess√≠veis**, facilitando a tomada de decis√£o por recrutadores ou analistas.

---

## üéØ Objetivo do Projeto
Demonstrar, de forma pr√°tica, conhecimentos em:
- Constru√ß√£o de pipelines ETL  
- Manipula√ß√£o e tratamento de dados com Pandas  
- Armazenamento em banco de dados relacional (SQLite)  
- Cria√ß√£o de dashboards interativos com Streamlit  
- Simula√ß√£o de problemas reais encontrados em dados do mercado  

---
